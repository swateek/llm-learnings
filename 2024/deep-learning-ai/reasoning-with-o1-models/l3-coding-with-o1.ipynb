{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "FbWoGOis4KoG"
   },
   "source": [
    "# Lesson 4: Coding with o1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import OpenAI key\n",
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Markdown\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "GPT_MODEL = 'gpt-4o-mini'\n",
    "O1_MODEL = 'o1-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Create\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(model, prompt):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI API to get a chat completion.\n",
    "\n",
    "    :param model: The model to use for the completion.\n",
    "    :param prompt: The prompt to send to the model.\n",
    "    :return: The completion response from the model.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_demo_prompt = \"\"\"Create an elegant, delightful React component for an Interview Feedback Form where:\n",
    "\n",
    "1. The interviewer rates candidates across multiple dimensions using rubrics\n",
    "2. Each rating must include specific evidence/examples\n",
    "3. The final recommendation should auto-calculate based on a weighted scoring system\n",
    "4. The UI should guide interviewers to give specific, behavioral feedback\n",
    "\n",
    "The goal is to enforce structured, objective feedback gathering. A smart model should:\n",
    "- Create a thoughtful rubric structure\n",
    "- Add helpful prompts/placeholders\n",
    "- Build in intelligent validation\n",
    "\n",
    "Make sure to\n",
    " - Call the element FeedbackForm\n",
    " - Start the code with \"use client\"\n",
    "\n",
    "Respond with the code only! Nothing else!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_code = get_chat_completion(GPT_MODEL, react_demo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image('gpt4_app_image.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_code = get_chat_completion(O1_MODEL, react_demo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o1_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image('o1_app_image.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Render the generated code yourself!\n",
    "There are two ways to try rendering this code yourself. The first is the easiest &#x1F642;  \n",
    "> Go to this [link](https://onecompiler.com/react), cut the code from the notebook and paste it into the editor.\n",
    " \n",
    " The 2nd is more complex:\n",
    "> Download a zip file that contains a react app and follow the instructions in the README. This file can be found by 1) Click on the \"File\" option on the top menu of the notebook and then 2) click on \"Open\". This will bring up a file view. 3) Click on the box next to the file \"app.zip\" 4) Click \"Download\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Edit\n",
    "\n",
    "The included code has some clear issues, such as multiple nested loops and a lack of error handling, and also is not very readable. Let's feed the code to both models, and see how they clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-generated code snippet with issues that need to be resolved.\n",
    "code_snippet = \"\"\"\n",
    "def process_orders(orders_list, settings={}, debug=False, notify_customer=True):\n",
    "    results = []\n",
    "    errors = []\n",
    "    notifications = []\n",
    "    # Process all orders\n",
    "    for i in range(0, len(orders_list)):\n",
    "        # Get order\n",
    "        order = orders_list[i]\n",
    "        try:\n",
    "            # Validate order has required fields\n",
    "            if 'id' in order and 'items' in order and 'customer' in order:\n",
    "                # Check customer info\n",
    "                if 'email' in order['customer'] and 'name' in order['customer']:\n",
    "                    # Validate items\n",
    "                    items_valid = True\n",
    "                    total = 0\n",
    "                    # Check each item\n",
    "                    for item in order['items']:\n",
    "                        if not ('product_id' in item and 'quantity' in item):\n",
    "                            items_valid = False\n",
    "                            errors.append(f\"Invalid item in order {order['id']}\")\n",
    "                            if debug == True:\n",
    "                                print(f\"Debug: Invalid item found in order {order['id']}\")\n",
    "                        else:\n",
    "                            # Calculate total\n",
    "                            if 'price' in item:\n",
    "                                total = total + (item['quantity'] * item['price'])\n",
    "                            else:\n",
    "                                items_valid = False\n",
    "                                errors.append(f\"Missing price in order {order['id']}\")\n",
    "                    # Process if items valid\n",
    "                    if items_valid == True:\n",
    "                        # Apply any discounts from settings\n",
    "                        if settings != {} and 'discount' in settings:\n",
    "                            total = total * (1 - settings['discount'])\n",
    "                        # Create processed order\n",
    "                        processed = {\n",
    "                            'order_id': order['id'],\n",
    "                            'customer_name': order['customer']['name'],\n",
    "                            'customer_email': order['customer']['email'],\n",
    "                            'total': total,\n",
    "                            'items_count': len(order['items'])\n",
    "                        }\n",
    "                        results.append(processed)\n",
    "                        # Send notification\n",
    "                        if notify_customer == True:\n",
    "                            try:\n",
    "                                # Create notification\n",
    "                                notification = {\n",
    "                                    'to': order['customer']['email'],\n",
    "                                    'subject': 'Order Processed',\n",
    "                                    'total': total\n",
    "                                }\n",
    "                                notifications.append(notification)\n",
    "                                if debug == True:\n",
    "                                    print(f\"Debug: Notification queued for order {order['id']}\")\n",
    "                            except Exception as e:\n",
    "                                errors.append(f\"Notification failed for order {order['id']}\")\n",
    "                else:\n",
    "                    errors.append(f\"Invalid customer data in order {order['id']}\")\n",
    "            else:\n",
    "                errors.append(f\"Missing required fields in order {order['id']}\")\n",
    "        except Exception as e:\n",
    "            # Add general error\n",
    "            errors.append(f\"Error processing order {order['id']}: {str(e)}\")\n",
    "            if debug == True:\n",
    "                print(f\"Debug: Error processing order {order['id']}: {str(e)}\")\n",
    "\n",
    "    # Print debug summary\n",
    "    if debug == True:\n",
    "        print(f\"Debug: Processed {len(results)} orders with {len(errors)} errors\")\n",
    "        print(f\"Debug: Queued {len(notifications)} notifications\")\n",
    "\n",
    "    return {\n",
    "        \"processed_orders\": results,\n",
    "        \"errors\": errors,\n",
    "        \"notifications\": notifications\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"I have some code that I'd like you to clean up and improve. Return only the updated code that fixes the issues: {code_snippet}\"\"\"\n",
    "gpt_code = get_chat_completion(GPT_MODEL, prompt)\n",
    "print(gpt_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_code = get_chat_completion(O1_MODEL, prompt)\n",
    "print(o1_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_chat_completion(O1_MODEL,f\"which code is better and why? Option 1: {gpt_code}... or Option 2: {o1_code}\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
